{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考`tutorials/rllib_exercise`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装，需要`tensorflow`以及`ray[rllib]`\n",
    "`pip install ray[rllib]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gym`会提供多种变体的simulator的MDP接口。具体的可以参见它的文档，它提供的环境有[gym env](https://gym.openai.com/envs/#classic_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created env: <TimeLimit<CartPoleEnv<CartPole-v0>>>\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "print('Created env:', env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回到MDP的初始状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The starting state is: [0.04582552 0.00954718 0.02526218 0.01461649]\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('The starting state is:', state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "action有 0 & 1(moving left and right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04601647 -0.18592778  0.02555451  0.31516166] 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "state, reward, done, info = env.step(action)\n",
    "print(state, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample policy got an average reward of 9.58.\n",
      "The second sample policy got an average reward of 29.25.\n"
     ]
    }
   ],
   "source": [
    "def rollout_policy(env, policy):\n",
    "    state = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Choose a random action (either 0 or 1).\n",
    "        action = policy(state)\n",
    "        \n",
    "        # Take the action in the environment.\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Update the cumulative reward.\n",
    "        cumulative_reward += reward\n",
    "\n",
    "    # Return the cumulative reward.\n",
    "    return cumulative_reward\n",
    "\n",
    "def sample_policy1(state):\n",
    "    return 0 if state[0] < 0 else 1\n",
    "\n",
    "def sample_policy2(state):\n",
    "    return 1 if state[0] < 0 else 0\n",
    "\n",
    "reward1 = np.mean([rollout_policy(env, sample_policy1) for _ in range(100)])\n",
    "reward2 = np.mean([rollout_policy(env, sample_policy2) for _ in range(100)])\n",
    "\n",
    "print('The first sample policy got an average reward of {}.'.format(reward1))\n",
    "print('The second sample policy got an average reward of {}.'.format(reward2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOAgent, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2018-10-29_22-02-36_3386/logs.\n",
      "Waiting for redis server at 127.0.0.1:51628 to respond...\n",
      "Waiting for redis server at 127.0.0.1:52034 to respond...\n",
      "Starting the Plasma object store with 1.61 GB memory.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8891/notebooks/ray_ui.ipynb?token=d05867c0b627172ef30ac650de3cfe5f13cb8170c5063776\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '222.195.64.115',\n",
       " 'redis_address': '222.195.64.115:51628',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/ray/session_2018-10-29_22-02-36_3386/sockets/plasma_store', manager_name=None, manager_port=None)],\n",
       " 'local_scheduler_socket_names': [],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2018-10-29_22-02-36_3386/sockets/raylet'],\n",
       " 'webui_url': 'http://localhost:8891/notebooks/ray_ui.ipynb?token=d05867c0b627172ef30ac650de3cfe5f13cb8170c5063776'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `num_workers` 被创建的actor的数量，决定了并行性的程度\n",
    "- `num_sgd_iter` epoces数量\n",
    "- `sgd_minibatch_size` SGD\n",
    "- `model` 包含一个`dict`，描述了神经网络的参数. `fcnet_hiddens` 是一个关于hidden layers大小的参数list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created LogSyncer for /home/drdh/ray_results/PPO_CartPole-v0_2018-10-29_22-02-39uco23dkt -> None\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2018-10-29 22:02:45,615\tINFO multi_gpu_optimizer.py:59 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 10\n",
    "config['sgd_minibatch_size'] = 256\n",
    "config['model']['fcnet_hiddens'] = [50, 50]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = PPOAgent(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdh/.local/lib/python3.7/site-packages/ray/tune/logger.py:183: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(value, float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2018-10-29_22-03-13\n",
      "done: false\n",
      "episode_len_mean: 23.116751269035532\n",
      "episode_reward_max: 64.0\n",
      "episode_reward_mean: 23.116751269035532\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 197\n",
      "episodes_total: 197\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.685346782207489\n",
      "  grad_time_ms: 2184.725\n",
      "  kl: 0.008550765924155712\n",
      "  load_time_ms: 126.242\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 4000\n",
      "  policy_loss: -0.01899544708430767\n",
      "  sample_time_ms: 3195.979\n",
      "  total_loss: 239.58241271972656\n",
      "  update_time_ms: 552.287\n",
      "  vf_explained_var: 0.0004984458209946752\n",
      "  vf_loss: 239.59970092773438\n",
      "iterations_since_restore: 1\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 6.155289649963379\n",
      "time_this_iter_s: 6.155289649963379\n",
      "time_total_s: 6.155289649963379\n",
      "timestamp: 1540821793\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "date: 2018-10-29_22-03-18\n",
      "done: false\n",
      "episode_len_mean: 27.36094674556213\n",
      "episode_reward_max: 81.0\n",
      "episode_reward_mean: 27.36094674556213\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 169\n",
      "episodes_total: 366\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.6446505784988403\n",
      "  grad_time_ms: 1794.934\n",
      "  kl: 0.018899360671639442\n",
      "  load_time_ms: 69.337\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 8000\n",
      "  policy_loss: -0.02883634902536869\n",
      "  sample_time_ms: 3457.837\n",
      "  total_loss: 364.56475830078125\n",
      "  update_time_ms: 281.305\n",
      "  vf_explained_var: 0.0003190716088283807\n",
      "  vf_loss: 364.58978271484375\n",
      "iterations_since_restore: 2\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 11.32423210144043\n",
      "time_this_iter_s: 5.168942451477051\n",
      "time_total_s: 11.32423210144043\n",
      "timestamp: 1540821798\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n",
      "date: 2018-10-29_22-03-23\n",
      "done: false\n",
      "episode_len_mean: 45.88\n",
      "episode_reward_max: 108.0\n",
      "episode_reward_mean: 45.88\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 97\n",
      "episodes_total: 463\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.6101590991020203\n",
      "  grad_time_ms: 1604.173\n",
      "  kl: 0.01158211287111044\n",
      "  load_time_ms: 46.721\n",
      "  num_steps_sampled: 12000\n",
      "  num_steps_trained: 12000\n",
      "  policy_loss: -0.019254865124821663\n",
      "  sample_time_ms: 3341.69\n",
      "  total_loss: 667.2818603515625\n",
      "  update_time_ms: 194.192\n",
      "  vf_explained_var: -0.004430830478668213\n",
      "  vf_loss: 667.298828125\n",
      "iterations_since_restore: 3\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 15.689827680587769\n",
      "time_this_iter_s: 4.365595579147339\n",
      "time_total_s: 15.689827680587769\n",
      "timestamp: 1540821803\n",
      "timesteps_since_restore: 12000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 12000\n",
      "training_iteration: 3\n",
      "\n",
      "date: 2018-10-29_22-03-26\n",
      "done: false\n",
      "episode_len_mean: 70.03\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 70.03\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 51\n",
      "episodes_total: 514\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.6150522828102112\n",
      "  grad_time_ms: 1449.987\n",
      "  kl: 0.002302023349329829\n",
      "  load_time_ms: 38.714\n",
      "  num_steps_sampled: 16000\n",
      "  num_steps_trained: 16000\n",
      "  policy_loss: -0.0061357589438557625\n",
      "  sample_time_ms: 3172.915\n",
      "  total_loss: 1534.8890380859375\n",
      "  update_time_ms: 150.443\n",
      "  vf_explained_var: 0.004029373172670603\n",
      "  vf_loss: 1534.8946533203125\n",
      "iterations_since_restore: 4\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 19.387046813964844\n",
      "time_this_iter_s: 3.697219133377075\n",
      "time_total_s: 19.387046813964844\n",
      "timestamp: 1540821806\n",
      "timesteps_since_restore: 16000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 16000\n",
      "training_iteration: 4\n",
      "\n",
      "date: 2018-10-29_22-03-30\n",
      "done: false\n",
      "episode_len_mean: 95.75\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 95.75\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 37\n",
      "episodes_total: 551\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5976054668426514\n",
      "  grad_time_ms: 1380.43\n",
      "  kl: 0.0027761992532759905\n",
      "  load_time_ms: 31.235\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 20000\n",
      "  policy_loss: -0.004993939772248268\n",
      "  sample_time_ms: 3059.647\n",
      "  total_loss: 1887.7276611328125\n",
      "  update_time_ms: 121.873\n",
      "  vf_explained_var: -0.0019497910980135202\n",
      "  vf_loss: 1887.7322998046875\n",
      "iterations_since_restore: 5\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 23.114073276519775\n",
      "time_this_iter_s: 3.7270264625549316\n",
      "time_total_s: 23.114073276519775\n",
      "timestamp: 1540821810\n",
      "timesteps_since_restore: 20000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 20000\n",
      "training_iteration: 5\n",
      "\n",
      "date: 2018-10-29_22-03-34\n",
      "done: false\n",
      "episode_len_mean: 125.56\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 125.56\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 29\n",
      "episodes_total: 580\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.6000431180000305\n",
      "  grad_time_ms: 1332.659\n",
      "  kl: 0.0014313755091279745\n",
      "  load_time_ms: 26.499\n",
      "  num_steps_sampled: 24000\n",
      "  num_steps_trained: 24000\n",
      "  policy_loss: -0.0021560078021138906\n",
      "  sample_time_ms: 2992.843\n",
      "  total_loss: 2434.03515625\n",
      "  update_time_ms: 103.627\n",
      "  vf_explained_var: 0.009747871197760105\n",
      "  vf_loss: 2434.03759765625\n",
      "iterations_since_restore: 6\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 26.895485639572144\n",
      "time_this_iter_s: 3.781412363052368\n",
      "time_total_s: 26.895485639572144\n",
      "timestamp: 1540821814\n",
      "timesteps_since_restore: 24000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 24000\n",
      "training_iteration: 6\n",
      "\n",
      "date: 2018-10-29_22-03-37\n",
      "done: false\n",
      "episode_len_mean: 145.85\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 145.85\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 603\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5580617189407349\n",
      "  grad_time_ms: 1274.928\n",
      "  kl: 0.004206763580441475\n",
      "  load_time_ms: 24.078\n",
      "  num_steps_sampled: 28000\n",
      "  num_steps_trained: 28000\n",
      "  policy_loss: -0.00250552361831069\n",
      "  sample_time_ms: 2930.788\n",
      "  total_loss: 1958.8206787109375\n",
      "  update_time_ms: 89.888\n",
      "  vf_explained_var: 0.007864109240472317\n",
      "  vf_loss: 1958.8228759765625\n",
      "iterations_since_restore: 7\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 30.408907413482666\n",
      "time_this_iter_s: 3.5134217739105225\n",
      "time_total_s: 30.408907413482666\n",
      "timestamp: 1540821817\n",
      "timesteps_since_restore: 28000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 28000\n",
      "training_iteration: 7\n",
      "\n",
      "date: 2018-10-29_22-03-41\n",
      "done: false\n",
      "episode_len_mean: 166.19\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 166.19\n",
      "episode_reward_min: 31.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 626\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5701552033424377\n",
      "  grad_time_ms: 1249.325\n",
      "  kl: 0.0003317898663226515\n",
      "  load_time_ms: 21.203\n",
      "  num_steps_sampled: 32000\n",
      "  num_steps_trained: 32000\n",
      "  policy_loss: 0.0005289112450554967\n",
      "  sample_time_ms: 2895.823\n",
      "  total_loss: 1782.74267578125\n",
      "  update_time_ms: 79.563\n",
      "  vf_explained_var: 0.014158197678625584\n",
      "  vf_loss: 1782.7420654296875\n",
      "iterations_since_restore: 8\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 34.148595094680786\n",
      "time_this_iter_s: 3.73968768119812\n",
      "time_total_s: 34.148595094680786\n",
      "timestamp: 1540821821\n",
      "timesteps_since_restore: 32000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 32000\n",
      "training_iteration: 8\n",
      "\n",
      "date: 2018-10-29_22-03-45\n",
      "done: false\n",
      "episode_len_mean: 184.08\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.08\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 649\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.57542484998703\n",
      "  grad_time_ms: 1227.89\n",
      "  kl: 9.357552335131913e-05\n",
      "  load_time_ms: 18.998\n",
      "  num_steps_sampled: 36000\n",
      "  num_steps_trained: 36000\n",
      "  policy_loss: 0.0009162957430817187\n",
      "  sample_time_ms: 2853.131\n",
      "  total_loss: 2269.73193359375\n",
      "  update_time_ms: 72.285\n",
      "  vf_explained_var: 0.022492019459605217\n",
      "  vf_loss: 2269.731201171875\n",
      "iterations_since_restore: 9\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 37.74150514602661\n",
      "time_this_iter_s: 3.592910051345825\n",
      "time_total_s: 37.74150514602661\n",
      "timestamp: 1540821825\n",
      "timesteps_since_restore: 36000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 36000\n",
      "training_iteration: 9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2018-10-29_22-03-48\n",
      "done: false\n",
      "episode_len_mean: 192.84\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.84\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 673\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.559470534324646\n",
      "  grad_time_ms: 1207.82\n",
      "  kl: 0.0008315223967656493\n",
      "  load_time_ms: 17.21\n",
      "  num_steps_sampled: 40000\n",
      "  num_steps_trained: 40000\n",
      "  policy_loss: -0.001442252891138196\n",
      "  sample_time_ms: 2814.336\n",
      "  total_loss: 2533.8740234375\n",
      "  update_time_ms: 65.945\n",
      "  vf_explained_var: 0.019507916644215584\n",
      "  vf_loss: 2533.875732421875\n",
      "iterations_since_restore: 10\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 41.25542593002319\n",
      "time_this_iter_s: 3.513920783996582\n",
      "time_total_s: 41.25542593002319\n",
      "timestamp: 1540821828\n",
      "timesteps_since_restore: 40000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 40000\n",
      "training_iteration: 10\n",
      "\n",
      "date: 2018-10-29_22-03-52\n",
      "done: false\n",
      "episode_len_mean: 196.72\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.72\n",
      "episode_reward_min: 153.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 697\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5405186414718628\n",
      "  grad_time_ms: 1089.441\n",
      "  kl: 0.0010755873518064618\n",
      "  load_time_ms: 4.743\n",
      "  num_steps_sampled: 44000\n",
      "  num_steps_trained: 44000\n",
      "  policy_loss: -0.006290989927947521\n",
      "  sample_time_ms: 2755.514\n",
      "  total_loss: 2299.943115234375\n",
      "  update_time_ms: 11.689\n",
      "  vf_explained_var: 0.012054026126861572\n",
      "  vf_loss: 2299.949462890625\n",
      "iterations_since_restore: 11\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 44.886804819107056\n",
      "time_this_iter_s: 3.6313788890838623\n",
      "time_total_s: 44.886804819107056\n",
      "timestamp: 1540821832\n",
      "timesteps_since_restore: 44000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 44000\n",
      "training_iteration: 11\n",
      "\n",
      "date: 2018-10-29_22-03-55\n",
      "done: false\n",
      "episode_len_mean: 197.73\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.73\n",
      "episode_reward_min: 158.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 720\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5498895645141602\n",
      "  grad_time_ms: 1047.671\n",
      "  kl: 0.0006307419389486313\n",
      "  load_time_ms: 3.612\n",
      "  num_steps_sampled: 48000\n",
      "  num_steps_trained: 48000\n",
      "  policy_loss: -0.006771554704755545\n",
      "  sample_time_ms: 2623.949\n",
      "  total_loss: 2294.682373046875\n",
      "  update_time_ms: 11.972\n",
      "  vf_explained_var: 0.02464900352060795\n",
      "  vf_loss: 2294.68896484375\n",
      "iterations_since_restore: 12\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 48.301886558532715\n",
      "time_this_iter_s: 3.415081739425659\n",
      "time_total_s: 48.301886558532715\n",
      "timestamp: 1540821835\n",
      "timesteps_since_restore: 48000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 48000\n",
      "training_iteration: 12\n",
      "\n",
      "date: 2018-10-29_22-03-59\n",
      "done: false\n",
      "episode_len_mean: 198.81\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.81\n",
      "episode_reward_min: 158.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 743\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5458745956420898\n",
      "  grad_time_ms: 1023.687\n",
      "  kl: 9.764309652382508e-05\n",
      "  load_time_ms: 3.927\n",
      "  num_steps_sampled: 52000\n",
      "  num_steps_trained: 52000\n",
      "  policy_loss: 0.001264654565602541\n",
      "  sample_time_ms: 2577.892\n",
      "  total_loss: 2120.3447265625\n",
      "  update_time_ms: 11.682\n",
      "  vf_explained_var: -0.00037353436346165836\n",
      "  vf_loss: 2120.34326171875\n",
      "iterations_since_restore: 13\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 51.96887707710266\n",
      "time_this_iter_s: 3.6669905185699463\n",
      "time_total_s: 51.96887707710266\n",
      "timestamp: 1540821839\n",
      "timesteps_since_restore: 52000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 52000\n",
      "training_iteration: 13\n",
      "\n",
      "date: 2018-10-29_22-04-02\n",
      "done: false\n",
      "episode_len_mean: 198.56\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.56\n",
      "episode_reward_min: 158.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 766\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5428038239479065\n",
      "  grad_time_ms: 1020.947\n",
      "  kl: 0.00102638965472579\n",
      "  load_time_ms: 2.6\n",
      "  num_steps_sampled: 56000\n",
      "  num_steps_trained: 56000\n",
      "  policy_loss: -0.0037913224659860134\n",
      "  sample_time_ms: 2560.766\n",
      "  total_loss: 1986.3104248046875\n",
      "  update_time_ms: 10.464\n",
      "  vf_explained_var: 0.005775741767138243\n",
      "  vf_loss: 1986.3143310546875\n",
      "iterations_since_restore: 14\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 55.441168785095215\n",
      "time_this_iter_s: 3.4722917079925537\n",
      "time_total_s: 55.441168785095215\n",
      "timestamp: 1540821842\n",
      "timesteps_since_restore: 56000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 56000\n",
      "training_iteration: 14\n",
      "\n",
      "date: 2018-10-29_22-04-06\n",
      "done: false\n",
      "episode_len_mean: 196.96\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.96\n",
      "episode_reward_min: 163.0\n",
      "episodes_this_iter: 25\n",
      "episodes_total: 791\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5358976721763611\n",
      "  grad_time_ms: 1046.254\n",
      "  kl: 0.00034769283956848085\n",
      "  load_time_ms: 2.577\n",
      "  num_steps_sampled: 60000\n",
      "  num_steps_trained: 60000\n",
      "  policy_loss: -0.00395027594640851\n",
      "  sample_time_ms: 2547.951\n",
      "  total_loss: 2276.096435546875\n",
      "  update_time_ms: 10.837\n",
      "  vf_explained_var: 0.004581622313708067\n",
      "  vf_loss: 2276.100341796875\n",
      "iterations_since_restore: 15\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 59.29750347137451\n",
      "time_this_iter_s: 3.856334686279297\n",
      "time_total_s: 59.29750347137451\n",
      "timestamp: 1540821846\n",
      "timesteps_since_restore: 60000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 60000\n",
      "training_iteration: 15\n",
      "\n",
      "date: 2018-10-29_22-04-10\n",
      "done: false\n",
      "episode_len_mean: 195.9\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.9\n",
      "episode_reward_min: 160.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 814\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5603187680244446\n",
      "  grad_time_ms: 1031.188\n",
      "  kl: 0.0013650119071826339\n",
      "  load_time_ms: 2.941\n",
      "  num_steps_sampled: 64000\n",
      "  num_steps_trained: 64000\n",
      "  policy_loss: -0.0018027698388323188\n",
      "  sample_time_ms: 2535.921\n",
      "  total_loss: 1901.8465576171875\n",
      "  update_time_ms: 11.046\n",
      "  vf_explained_var: 0.008323939517140388\n",
      "  vf_loss: 1901.848388671875\n",
      "iterations_since_restore: 16\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 62.81056022644043\n",
      "time_this_iter_s: 3.513056755065918\n",
      "time_total_s: 62.81056022644043\n",
      "timestamp: 1540821850\n",
      "timesteps_since_restore: 64000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 64000\n",
      "training_iteration: 16\n",
      "\n",
      "date: 2018-10-29_22-04-14\n",
      "done: false\n",
      "episode_len_mean: 194.26\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.26\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 838\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5534089207649231\n",
      "  grad_time_ms: 1040.735\n",
      "  kl: 0.002067766385152936\n",
      "  load_time_ms: 2.159\n",
      "  num_steps_sampled: 68000\n",
      "  num_steps_trained: 68000\n",
      "  policy_loss: -0.00594349903985858\n",
      "  sample_time_ms: 2552.01\n",
      "  total_loss: 1647.171630859375\n",
      "  update_time_ms: 11.213\n",
      "  vf_explained_var: 0.02261900156736374\n",
      "  vf_loss: 1647.1776123046875\n",
      "iterations_since_restore: 17\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 66.57534050941467\n",
      "time_this_iter_s: 3.764780282974243\n",
      "time_total_s: 66.57534050941467\n",
      "timestamp: 1540821854\n",
      "timesteps_since_restore: 68000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 68000\n",
      "training_iteration: 17\n",
      "\n",
      "date: 2018-10-29_22-04-17\n",
      "done: false\n",
      "episode_len_mean: 193.66\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.66\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 861\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5351402163505554\n",
      "  grad_time_ms: 1031.842\n",
      "  kl: 0.00043868549983017147\n",
      "  load_time_ms: 2.173\n",
      "  num_steps_sampled: 72000\n",
      "  num_steps_trained: 72000\n",
      "  policy_loss: -0.003288037609308958\n",
      "  sample_time_ms: 2545.885\n",
      "  total_loss: 1453.6910400390625\n",
      "  update_time_ms: 11.709\n",
      "  vf_explained_var: 0.0005217353464104235\n",
      "  vf_loss: 1453.6944580078125\n",
      "iterations_since_restore: 18\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 70.17129802703857\n",
      "time_this_iter_s: 3.5959575176239014\n",
      "time_total_s: 70.17129802703857\n",
      "timestamp: 1540821857\n",
      "timesteps_since_restore: 72000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 72000\n",
      "training_iteration: 18\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2018-10-29_22-04-21\n",
      "done: false\n",
      "episode_len_mean: 192.96\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.96\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 25\n",
      "episodes_total: 886\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5419458746910095\n",
      "  grad_time_ms: 1036.222\n",
      "  kl: 0.0014677790459245443\n",
      "  load_time_ms: 2.255\n",
      "  num_steps_sampled: 76000\n",
      "  num_steps_trained: 76000\n",
      "  policy_loss: 0.0014283251948654652\n",
      "  sample_time_ms: 2565.785\n",
      "  total_loss: 1685.67138671875\n",
      "  update_time_ms: 11.286\n",
      "  vf_explained_var: 0.026106519624590874\n",
      "  vf_loss: 1685.669921875\n",
      "iterations_since_restore: 19\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 74.01923823356628\n",
      "time_this_iter_s: 3.84794020652771\n",
      "time_total_s: 74.01923823356628\n",
      "timestamp: 1540821861\n",
      "timesteps_since_restore: 76000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 76000\n",
      "training_iteration: 19\n",
      "\n",
      "date: 2018-10-29_22-04-25\n",
      "done: false\n",
      "episode_len_mean: 191.52\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.52\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 909\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5322585701942444\n",
      "  grad_time_ms: 1030.01\n",
      "  kl: 0.00025993294548243284\n",
      "  load_time_ms: 2.271\n",
      "  num_steps_sampled: 80000\n",
      "  num_steps_trained: 80000\n",
      "  policy_loss: 0.0011537522077560425\n",
      "  sample_time_ms: 2579.957\n",
      "  total_loss: 1443.8040771484375\n",
      "  update_time_ms: 11.827\n",
      "  vf_explained_var: 0.030005093663930893\n",
      "  vf_loss: 1443.802734375\n",
      "iterations_since_restore: 20\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 77.61640977859497\n",
      "time_this_iter_s: 3.5971715450286865\n",
      "time_total_s: 77.61640977859497\n",
      "timestamp: 1540821865\n",
      "timesteps_since_restore: 80000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 80000\n",
      "training_iteration: 20\n",
      "\n",
      "date: 2018-10-29_22-04-28\n",
      "done: false\n",
      "episode_len_mean: 191.74\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.74\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 25\n",
      "episodes_total: 934\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5456025004386902\n",
      "  grad_time_ms: 1026.557\n",
      "  kl: 0.00011508258467074484\n",
      "  load_time_ms: 2.22\n",
      "  num_steps_sampled: 84000\n",
      "  num_steps_trained: 84000\n",
      "  policy_loss: -0.004871404264122248\n",
      "  sample_time_ms: 2585.088\n",
      "  total_loss: 1823.36083984375\n",
      "  update_time_ms: 11.955\n",
      "  vf_explained_var: 0.012942103669047356\n",
      "  vf_loss: 1823.365966796875\n",
      "iterations_since_restore: 21\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 81.26893639564514\n",
      "time_this_iter_s: 3.652526617050171\n",
      "time_total_s: 81.26893639564514\n",
      "timestamp: 1540821868\n",
      "timesteps_since_restore: 84000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 84000\n",
      "training_iteration: 21\n",
      "\n",
      "date: 2018-10-29_22-04-32\n",
      "done: false\n",
      "episode_len_mean: 191.15\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.15\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 958\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5575609803199768\n",
      "  grad_time_ms: 1027.748\n",
      "  kl: 0.0018825357547029853\n",
      "  load_time_ms: 2.217\n",
      "  num_steps_sampled: 88000\n",
      "  num_steps_trained: 88000\n",
      "  policy_loss: 0.005060418043285608\n",
      "  sample_time_ms: 2617.667\n",
      "  total_loss: 1693.8631591796875\n",
      "  update_time_ms: 12.408\n",
      "  vf_explained_var: 0.007786059286445379\n",
      "  vf_loss: 1693.8580322265625\n",
      "iterations_since_restore: 22\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 85.02943778038025\n",
      "time_this_iter_s: 3.7605013847351074\n",
      "time_total_s: 85.02943778038025\n",
      "timestamp: 1540821872\n",
      "timesteps_since_restore: 88000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 88000\n",
      "training_iteration: 22\n",
      "\n",
      "date: 2018-10-29_22-04-36\n",
      "done: false\n",
      "episode_len_mean: 191.0\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.0\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 982\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5300271511077881\n",
      "  grad_time_ms: 1039.974\n",
      "  kl: 0.0027119258884340525\n",
      "  load_time_ms: 1.915\n",
      "  num_steps_sampled: 92000\n",
      "  num_steps_trained: 92000\n",
      "  policy_loss: -0.00764463422819972\n",
      "  sample_time_ms: 2624.758\n",
      "  total_loss: 1486.124755859375\n",
      "  update_time_ms: 11.845\n",
      "  vf_explained_var: 0.018094277009367943\n",
      "  vf_loss: 1486.13232421875\n",
      "iterations_since_restore: 23\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 88.8769588470459\n",
      "time_this_iter_s: 3.8475210666656494\n",
      "time_total_s: 88.8769588470459\n",
      "timestamp: 1540821876\n",
      "timesteps_since_restore: 92000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 92000\n",
      "training_iteration: 23\n",
      "\n",
      "date: 2018-10-29_22-04-40\n",
      "done: false\n",
      "episode_len_mean: 191.37\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.37\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 1005\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5198934078216553\n",
      "  grad_time_ms: 1043.508\n",
      "  kl: 0.0014067367883399129\n",
      "  load_time_ms: 2.034\n",
      "  num_steps_sampled: 96000\n",
      "  num_steps_trained: 96000\n",
      "  policy_loss: 0.005190877243876457\n",
      "  sample_time_ms: 2639.201\n",
      "  total_loss: 1503.32666015625\n",
      "  update_time_ms: 12.122\n",
      "  vf_explained_var: 0.010698148049414158\n",
      "  vf_loss: 1503.3216552734375\n",
      "iterations_since_restore: 24\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 92.53494119644165\n",
      "time_this_iter_s: 3.657982349395752\n",
      "time_total_s: 92.53494119644165\n",
      "timestamp: 1540821880\n",
      "timesteps_since_restore: 96000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 96000\n",
      "training_iteration: 24\n",
      "\n",
      "date: 2018-10-29_22-04-43\n",
      "done: false\n",
      "episode_len_mean: 191.69\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.69\n",
      "episode_reward_min: 150.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 1029\n",
      "experiment_id: 2b493b042b7842dbb6238a047536ffdf\n",
      "hostname: lx\n",
      "info:\n",
      "  cur_lr: 4.999999873689376e-05\n",
      "  entropy: 0.5031793713569641\n",
      "  grad_time_ms: 996.721\n",
      "  kl: 0.0018887871410697699\n",
      "  load_time_ms: 2.111\n",
      "  num_steps_sampled: 100000\n",
      "  num_steps_trained: 100000\n",
      "  policy_loss: -0.008106399327516556\n",
      "  sample_time_ms: 2653.187\n",
      "  total_loss: 1761.5706787109375\n",
      "  update_time_ms: 11.911\n",
      "  vf_explained_var: 0.008299811743199825\n",
      "  vf_loss: 1761.578857421875\n",
      "iterations_since_restore: 25\n",
      "node_ip: 222.195.64.115\n",
      "pid: 3386\n",
      "policy_reward_mean: {}\n",
      "time_since_restore: 96.06159567832947\n",
      "time_this_iter_s: 3.5266544818878174\n",
      "time_total_s: 96.06159567832947\n",
      "timestamp: 1540821883\n",
      "timesteps_since_restore: 100000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 100000\n",
      "training_iteration: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储一下模型，再恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created LogSyncer for /home/drdh/ray_results/PPO_CartPole-v0_2018-10-29_22-04-46i_skv_mr -> None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/drdh/ray_results/PPO_CartPole-v0_2018-10-29_22-02-39uco23dkt/checkpoint_25xflwn0j9/checkpoint-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2018-10-29 22:04:48,392\tINFO multi_gpu_optimizer.py:59 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = agent.save()\n",
    "print(checkpoint_path)\n",
    "\n",
    "trained_config = config.copy()\n",
    "\n",
    "test_agent = PPOAgent(trained_config, 'CartPole-v0')\n",
    "test_agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用restore的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
